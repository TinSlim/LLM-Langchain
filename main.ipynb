{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# LLM AWS\n",
    "import boto3\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "\n",
    "# LLM Azure\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Output Parser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claude - AWS\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "AWS_SECRET_KEY = os.getenv('AWS_SECRET_KEY')\n",
    "REGION_NAME = os.getenv('REGION_NAME')\n",
    "\n",
    "boto3.setup_default_session(aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                            aws_secret_access_key=AWS_SECRET_KEY,\n",
    "                            region_name=REGION_NAME)\n",
    "\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "llm_claude = ChatBedrock(\n",
    "    credentials_profile_name=\"bedrock-admin\",\n",
    "    model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    client=bedrock_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT4o-mini - Azure\n",
    "AZURE_APIKEY = os.environ[\"AZURE_OPENAI_APIKEY\"]\n",
    "AZURE_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]\n",
    "AZURE_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "\n",
    "llm_openai = AzureChatOpenAI(\n",
    "    deployment_name= AZURE_DEPLOYMENT,\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    api_key= AZURE_APIKEY,\n",
    "    azure_endpoint= AZURE_ENDPOINT,\n",
    "    openai_api_type= \"azure\",\n",
    "    temperature= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gemini-flash-2 - GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain\n",
    "\n",
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nRecibirás una lista de palabras, que pueden o no relacionarse entre ellas.\\nDebes generar una palabra que se relacione con las que te entregué y se pueda incluir en la lista haciendo que mantenga el sentido.\\n\\nLas palabras son:\\n['ají', 'merkén', 'chile']\\n\\nLa respuesta debes entregármela como un JSON:\\nrespuesta: Es la respuesta que encontraste\\njustificacion: Justificación corta de por qué elegiste esa palabra\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "prompt_related_word = PromptTemplate.from_template(\"\"\"\n",
    "Recibirás una lista de palabras, que pueden o no relacionarse entre ellas.\n",
    "Debes generar una palabra que se relacione con las que te entregué y se pueda incluir en la lista haciendo que mantenga el sentido.\n",
    "\n",
    "Las palabras son:\n",
    "{palabras}\n",
    "\n",
    "La respuesta debes entregármela como un JSON:\n",
    "respuesta: Es la respuesta que encontraste\n",
    "justificacion: Justificación corta de por qué elegiste esa palabra\n",
    "\"\"\")\n",
    "\n",
    "prompt_related_word.format(palabras=[\"ají\",\"merkén\",\"chile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser\n",
    "parser_json = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude: {'respuesta': 'picante', 'justificacion': \"La palabra 'picante' se relaciona con las palabras 'ají', 'merkén' y 'chile', ya que todas ellas se refieren a tipos de especias o condimentos que se caracterizan por su sabor picante.\"}\n",
      "OpenAI: {'respuesta': 'pimiento', 'justificacion': 'El pimiento es un término general que se relaciona con el ají y el chile, ya que ambos son tipos de pimientos picantes.'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_related_word | llm_claude | parser_json\n",
    "print(\"Claude:\", chain.invoke({\"palabras\":[\"ají\",\"merkén\",\"chile\"]}))\n",
    "\n",
    "chain = prompt_related_word | llm_openai | parser_json\n",
    "print(\"OpenAI:\", chain.invoke({\"palabras\":[\"ají\",\"merkén\",\"chile\"]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "horas = {1,2,3,19,22}\n",
    "total = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,21,22,23,24}\n",
    "\n",
    "@tool\n",
    "def agendar_hora(hora: int):\n",
    "    \"\"\"\n",
    "    Recibe una hora para agendar, que va desde 0 a 24 y agenda la hora\n",
    "    \"\"\"\n",
    "    return horas.add(hora)\n",
    "\n",
    "@tool\n",
    "def disponibilidad_horaria(hora: int):\n",
    "    \"\"\"\n",
    "    Recibe una hora, que va desde 0 a 24 y consulta en la agenda para ver si está disponible\n",
    "    \"\"\"\n",
    "    if hora in horas:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "@tool\n",
    "def listar_horas_disponibles():\n",
    "    \"\"\"\n",
    "    Lista las horas disponibles para agendar\n",
    "    \"\"\"\n",
    "    return total - horas\n",
    "\n",
    "\n",
    "\n",
    "def agendar_hora_func(hora: int):\n",
    "    \"\"\"\n",
    "    Recibe una hora para agendar, que va desde 0 a 24 y agenda la hora\n",
    "    \"\"\"\n",
    "    return horas.add(hora)\n",
    "\n",
    "\n",
    "def disponibilidad_horaria_func(hora: int):\n",
    "    \"\"\"\n",
    "    Recibe una hora, que va desde 0 a 24 y consulta en la agenda para ver si está disponible\n",
    "    \"\"\"\n",
    "    if hora in horas:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def listar_horas_disponibles_func():\n",
    "    \"\"\"\n",
    "    Lista las horas disponibles para agendar\n",
    "    \"\"\"\n",
    "    return total - horas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatBedrock(client=<botocore.client.BedrockRuntime object at 0x000001A2414D6E50>, credentials_profile_name='bedrock-admin', model_id='anthropic.claude-3-haiku-20240307-v1:0'), kwargs={'tools': [{'name': 'agendar_hora', 'description': 'Recibe una hora para agendar, que va desde 0 a 24 y agenda la hora', 'input_schema': {'properties': {'hora': {'type': 'integer'}}, 'required': ['hora'], 'type': 'object'}}, {'name': 'disponibilidad_horaria', 'description': 'Recibe una hora, que va desde 0 a 24 y consulta en la agenda para ver si está disponible', 'input_schema': {'properties': {'hora': {'type': 'integer'}}, 'required': ['hora'], 'type': 'object'}}, {'name': 'listar_horas_disponibles', 'description': 'Lista las horas disponibles para agendar', 'input_schema': {'properties': {}, 'type': 'object'}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [agendar_hora, disponibilidad_horaria, listar_horas_disponibles]\n",
    "functions = {\n",
    "    \"agendar_hora\": agendar_hora,\n",
    "    \"disponibilidad_horaria\": disponibilidad_horaria,\n",
    "    \"listar_horas_disponibles\": listar_horas_disponibles\n",
    "}\n",
    "\n",
    "llm_tools = llm_claude.bind_tools(tools)\n",
    "llm_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Imprime horas\n",
    "    horas_sort = list(horas)\n",
    "    horas_sort.sort()\n",
    "    print(\"\\033[32m\",\"Horas en uso:\",horas_sort)\n",
    "\n",
    "    # Recibe entrada\n",
    "    print(\"\\033[35mInput:\",end=\"\")\n",
    "    res = input(\"\")\n",
    "    print(f\"\\033[35m\",res)\n",
    "\n",
    "    messages = [\n",
    "    (\"human\", res),\n",
    "    ]\n",
    "\n",
    "    ans = llm_tools.invoke(messages)\n",
    "    \n",
    "\n",
    "    if (ans.tool_calls):\n",
    "        for call in ans.tool_calls:\n",
    "            \n",
    "            function_name = call['name']\n",
    "            function_args = call['args']\n",
    "\n",
    "            if function_name == \"listar_horas_disponibles\":\n",
    "                print(listar_horas_disponibles_func())\n",
    "            elif function_name == \"disponibilidad_horaria\":\n",
    "                print(disponibilidad_horaria_func(function_args['hora']))\n",
    "            elif function_name == \"agendar_hora\":\n",
    "                agendar_hora_func(function_args['hora'])\n",
    "                print(f\"agendó una hora '{function_args['hora']}'\")\n",
    "            print()\n",
    "    else:\n",
    "        print(ans.content)\n",
    "        print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
